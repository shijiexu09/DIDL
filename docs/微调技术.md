大模型微调方法
- Adapter-Tuning  
介绍  
Adapter是一种微调技术，它通过在预训练模型中添加小型的、可学习的模块来适配特定任务。这些模块可以插入到现有层中，允许模型在学习新任务时保留大部分原有参数，从而减少额外的计算成本和内存占用。
Adapter尤其适合在参数量巨大的模型中进行微调，因为它能够实现更高效的任务适应，同时最小化对原始模型结构的干扰。

实践  
coming soon...  

- Prefix-Tuning  
介绍
Prefix-Tuning是一种针对自注意力机制的微调方法，它通过向输入序列添加一组可训练的前缀（prefix）向量来引导模型的注意力。这些前缀向量与模型的键（keys）和值（values）拼接，形成新的输入表示。
Prefix-Tuning的优势在于其灵活性，允许不同的任务使用不同的前缀，且不需要更改原始模型的架构或参数
实践  
coming soon...  

- Prompt-Tuning
介绍  
Prompt-Tuning是一种利用前缀调整来微调大型预训练语言模型的方法。它通过将任务相关的提示转化为模型输入的一部分，以产生相应任务的输出

实践  
coming soon...  

- P-Tuning  
介绍  
P-Tuning是一种高效微调预训练语言模型的方法，它通过引入可学习的连续提示（continuous prompts）来实现模型的微调。这些连续提示被转换成模型可以理解的嵌入表示，并经过LSTM和MLP结构处理，以捕捉复杂的任务依赖性。
P-Tuning的优势在于其高效性和灵活性，能够在不改变原始模型其他参数的情况下，仅通过优化这些连续提示来适应不同的下游任务

实践  
coming soon...  

- P-Tuning v2  
介绍  
P-Tuning v2是P-Tuning的改进版本，它引入了动态参数调整策略来进一步提升微调的效率和性能。这种方法根据当前迭代次数或已更新参数数量动态调整要更新的参数比例，从而在迭代初期选择更多的参数进行更新，
随着迭代的进行，逐渐减少选择的参数数量。这种策略使得P-Tuning v2在保持高效性的同时，能够更好地平衡模型的学习和泛化能力

coming soon...  

- LoRA  
介绍  
Low-Rank Adaptation是一种适用于大模型微调的低秩逼近方法。它通过在预训练模型的层间添加低秩矩阵来引入新参数，这些矩阵可以捕捉任务相关的信息而不会对原始模型参数造成显著影响。
LoRA方法的优势在于其能够有效地减少微调过程中所需的额外计算资源和存储需求，同时保持模型的性能

实践  
coming soon...  


Refer  
https://www.zhihu.com/pin/1776017525886824448